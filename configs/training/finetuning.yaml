# Fine-tuning Configuration
# Physics-constrained fine-tuning with conservation laws and known limits

# Training data
data:
  train_path: data/finetune_train
  val_path: data/finetune_val
  batch_size: 16
  num_workers: 4
  shuffle: true
  
  # Focus on specific conditions
  materials: [Si]  # Can specify subset for focused fine-tuning
  density_range: [0.01, 5.0]  # particles/nm³
  energy_range: [1.0, 50.0]  # MeV
  temperature_range: [300.0, 5000.0]  # K
  
  # Include edge cases
  include_low_density: true
  include_high_temperature: true

# Pretrained checkpoint
pretrained_checkpoint: checkpoints/pretraining/best_model.pt
freeze_encoder: false  # Whether to freeze encoder during fine-tuning

# Optimizer
optimizer:
  type: adamw
  lr: 1.0e-4  # Lower than pretraining
  weight_decay: 1.0e-5
  betas: [0.9, 0.999]
  eps: 1.0e-8

# Learning rate scheduler
scheduler:
  type: cosine_annealing
  T_max: 50  # epochs
  eta_min: 1.0e-7
  warmup_epochs: 3
  warmup_start_lr: 1.0e-6

# Training loop
training:
  epochs: 50
  gradient_clip_norm: 0.5
  log_interval: 10  # batches
  val_interval: 1  # epochs
  checkpoint_interval: 5  # epochs
  early_stopping_patience: 10

# Loss weights
loss_weights:
  prediction: 1.0
  conservation: 0.1
  physics_limits: 0.05

# Conservation loss weights
conservation_weights:
  energy: 1.0
  momentum: 1.0
  charge: 1.0

# Physics limit loss weights
physics_weights:
  vlasov: 1.0
  maxwell_boltzmann: 1.0
  stopping_power: 1.0

# Physics constraints
physics_constraints:
  # Vlasov limit
  vlasov_density_threshold: 0.01  # particles/nm³
  
  # Maxwell-Boltzmann limit
  mb_temperature_threshold: 1000.0  # K
  
  # Stopping power
  use_stopping_power_table: true
  stopping_power_table_path: data/stopping_power.json

# Logging
logging:
  use_tensorboard: true
  tensorboard_dir: logs/finetuning
  use_wandb: false
  wandb_project: multi-scale-physics
  wandb_entity: null
  log_gradients: false
  log_weights: false
  log_conservation_errors: true

# Checkpointing
checkpointing:
  save_dir: checkpoints/finetuning
  save_best_only: false
  monitor_metric: val_loss
  mode: min
